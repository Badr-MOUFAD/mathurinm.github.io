# jemdoc: menu{MENU}{index.html}, nofooter
==Mathurin Massias

~~~
{}{img_left}{assets/photo.jpg}{alt text}{191}{213}
Junior researcher \n
Inria  \n
E-mail: /mathurin.massias/ \[@\] gmail \[DOT\] com
~~~

== About me

I am a Junior researcher (Chargé de recherche) in Inria Lyon, in the OCKHAM (ex-DANTE) team led by Rémi Gribonval, working in optimization for Machine Learning.

From January 2020 to October 2021, I was a post-doc at University of Genova, where I worked with [http://web.mit.edu/lrosasco/www/ Lorenzo Rosasco] and [http://www.dima.unige.it/~villa/ Silvia Villa] to develop new algorithms for implicit regularization.
I hold a PhD from Télécom Paris and Inria Saclay
([https://team.inria.fr/parietal/ Parietal Team]), under the supervision of
    [https://josephsalmon.eu/ Joseph Salmon]
and [http://alexandre.gramfort.net/ Alexandre Gramfort].
In my PhD, I improved the efficiency of brain signals reconstruction algorithms
(more details [http://www.theses.fr/s163051
    here]), which involves optimization, sparsity and high dimensional statistics.

I have a keen interest in the Python programming language: I am the lead developer
of [https://mathurinm.github.io/celer/ celer] (fastest Lasso solver) and [https://contrib.scikit-learn.org/skglm/ skglm] (fast and flexible sklearn GLMs). I am also a core developer of [https://github.com/benchopt/benchopt benchopt], a benchmarking suite that makes optimization benchmarks easy, transparent and reproducible.
\n
To foster scientific reproducibility, my papers usually come with Python packages to reproduce my experiments and make my code available to the community (e.g. [https://mathurinm.github.io/andersoncd/auto_examples/index.html Anderson acceleration for coordinate descent] or [https://LCSL.github.io/iterreg/auto_examples/index.html Iterative regularization for convex regularizers])
\n
I also contribute to [http://scikit-learn.org/ scikit-learn], [https://martinos.org/mne/stable/index.html MNE], and [https://github.com/qb3/sparse-ho sparse-ho].

\n
You can find more details on my résumé
    ([./assets/pdf/CV_Mathurin_MASSIAS.pdf French (01\/2021)]\/[./assets/pdf/CV_Mathurin_MASSIAS_EN.pdf English (07\/2022)]) and my
 [research.html list of publications].

== Job offers
- M2 internship offer on improving sparse penalties with Emmanuel Soubiès [./assets/pdf/sujet_stage_M2_nonconvexity.pdf here]


== News
- I gave a course on convex optimization at the [https://wmat.pwr.edu.pl/en/cm2022 Computation and Modelling school] in Wrocław; resources are on my teaching page.
- [https://github.com/mathurinm/celer celer 0.7] is released, with a fast ElasticNet solver thanks to [https://github.com/Badr-MOUFAD Badr Moufad]!
- We have integrated [https://contrib.scikit-learn.org/skglm skglm] into scikit-learn, providing a customizable and accelerated solver for sparse GLMs in python.
- [./assets/pdf/slides_mlmtp.pdf Slides ] for my talk at ML-MTP (Montpellier)
- Our two papers on Iterative regularization for convex regularizers (w. C. Molinari, L. Rosasco and S. Villa) and Anderson acceleration of coordinate descent (w. Q. Bertrand) got accepted to AISTATS 2021.
- Slides for my presentation [./assets/pdf/presentation_dante.pdf Efficient approaches to regularized inverse problems] in the DANTE team (Lyon)
- [https://github.com/mathurinm/celer celer 0.6] is released: along with the fast sklearn Group Lasso solver, the Lasso class now supports weights in the penalty, paving the way for an efficient Adaptive Lasso (iterative reweighted L1) which should be released in version 0.7.
- Slides for my presentation [./assets/pdf/presentation_gaia.pdf Efficient approaches to regularized inverse problems] in the GAIA team of the GIPSA-lab (Grenoble)
- I was awarded the [https://www.fondation-hadamard.fr/fr/pgmo/students/phdawards Programme Gaspard Monge Optimisation] PhD prize!
- I was awarded [https://www.telecom-paris.fr/fr/doctorat/grade/prix-de-these Telecom Paris' 2020 PhD prize]! A warm thank you to my advisors Alexandre Gramfort, Joseph Salmon and coauthor Quentin Bertrand
- We recently started the [https://github.com/benchopt/benchopt benchopt] package to automate benchmarks of optimization algorithms on popular Machine Learning tasks
- I defended my PhD! Slides are [./assets/pdf/slides_defense.pdf here], and [https://tel.archives-ouvertes.fr/tel-02401628 here] is the manuscript. Starting next January I'll be a postdoc in Lorenzo Rosasco's Lab in Genova
- I joined [http://ibis.t.u-tokyo.ac.jp/suzuki/ Taiji Suzuki's lab] for an internship in Tokyo from Feb. 2019 to May 2019
