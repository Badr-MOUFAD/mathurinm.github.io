# jemdoc: menu{MENU}{index.html}, nofooter
==Mathurin Massias

~~~
{}{img_left}{assets/photo.jpg}{alt text}{191}{213}
Junior researcher \n
Inria  \n
E-mail: /mathurin.massias/ \[@\] gmail \[DOT\] com
~~~

== About me

I am a researcher (Chargé de recherche) in Inria Lyon, in the OCKHAM (ex-DANTE) team led by Rémi Gribonval, working in optimization for Machine Learning.

From January 2020 to October 2021, I was a post-doc at University of Genova, where I worked with [http://web.mit.edu/lrosasco/www/ Lorenzo Rosasco] and [http://www.dima.unige.it/~villa/ Silvia Villa] to develop new algorithms for implicit regularization.
I hold a PhD from Télécom Paris and Inria Saclay
([https://team.inria.fr/parietal/ Parietal Team]), under the supervision of
    [https://josephsalmon.eu/ Joseph Salmon]
and [http://alexandre.gramfort.net/ Alexandre Gramfort].
In my PhD, I improved the efficiency of brain signals reconstruction algorithms
(more details [http://www.theses.fr/s163051
    here]), which involves optimization, sparsity and high dimensional statistics.

I have a keen interest in the Python programming language: I am the lead developer
of [https://mathurinm.github.io/celer/ celer] (fastest Lasso solver) and [https://contrib.scikit-learn.org/skglm/ skglm] (fast and flexible sklearn GLMs). I am also a core developer of [https://github.com/benchopt/benchopt benchopt], a benchmarking framework that makes optimization benchmarks easy, transparent and reproducible.
\n
To foster scientific reproducibility, my papers usually come with Python packages to reproduce my experiments and make my code available to the community (e.g. [https://mathurinm.github.io/andersoncd/auto_examples/index.html Anderson acceleration for coordinate descent] or [https://LCSL.github.io/iterreg/auto_examples/index.html Iterative regularization for convex regularizers])
\n
I am an associate editor for [https://computo.sfds.asso.fr/ Computo], a journal promoting reproducibility through a novel publication format, and for TMLR.

\n
You can find more details on my résumé
    ([./assets/pdf/CV_Mathurin_MASSIAS.pdf French (01\/2021)]\/[./assets/pdf/CV_Mathurin_MASSIAS_EN.pdf English (02\/2024)]) and my
 [research.html list of publications].

\n
I co-organize the [https://www.ens-lyon.fr/PHYSIQUE/seminars/machine-learning-and-signal-processing Machine Learning and Signal Processing seminar] at ENS Lyon, send me a message if you want to present your work there!


== Team and alumni
- [https://perceptronium.github.io Can Pouliquen], PhD student with Titouan Vayer and Paulo Gonçalves, since November 2022
- [https://annegnx.github.io Anne Gagneux], PhD student from MVA co-supervised with Emmanuel Soubiès and Rémi Gribonval, since April 2023
- [https://github.com/Badr-MOUFAD/ Badr Moufad], research engineer, April 2022 - Dec. 2023. Now Phd student at Ecole Polytechnique.

== Job offers
- None currently available, but please contact me if interested.


== News
- We organize the SMAI MODE days in Lyon, from march 27th to march 29th. A minicourse on optimal transport by Gabriel Peyré and Yann Brenier will be held at ENS de Lyon on the 25th and 26th.
- With Titouan Vayer and the help of GDR MIA we organized a thematic day on dimension reduction at ENS Lyon. The final planning is available [https://gdr-mia.math.cnrs.fr/events/dimreduc here].
- [./assets/pdf/presentation_cep.pdf Slides] for my presentation at Inria Comité des Equipes Projets
- Our paper on Coordinate descent for SLOPE was accepted to AISTATS'23! [./assets/pdf/slides_slope.pdf Slides of the paper] presented at the Statistical Learning Seminar
- 2 papers accepted at Neurips'22, on benchopt and skglm.
- I gave a course on convex optimization at the [https://wmat.pwr.edu.pl/en/cm2022 Computation and Modelling school] in Wrocław; resources are on my teaching page.
- [https://github.com/mathurinm/celer celer 0.7] is released, with a fast ElasticNet solver thanks to [https://github.com/Badr-MOUFAD Badr Moufad]!
- We have integrated [https://contrib.scikit-learn.org/skglm skglm] into scikit-learn, providing a customizable and accelerated solver for sparse GLMs in python.
- [./assets/pdf/slides_mlmtp.pdf Slides ] for my talk at ML-MTP (Montpellier)
- Our two papers on Iterative regularization for convex regularizers (w. C. Molinari, L. Rosasco and S. Villa) and Anderson acceleration of coordinate descent (w. Q. Bertrand) got accepted to AISTATS 2021.
- Slides for my presentation [./assets/pdf/presentation_dante.pdf Efficient approaches to regularized inverse problems] in the DANTE team (Lyon)
- [https://github.com/mathurinm/celer celer 0.6] is released: along with the fast sklearn Group Lasso solver, the Lasso class now supports weights in the penalty, paving the way for an efficient Adaptive Lasso (iterative reweighted L1) which should be released in version 0.7.
- Slides for my presentation [./assets/pdf/presentation_gaia.pdf Efficient approaches to regularized inverse problems] in the GAIA team of the GIPSA-lab (Grenoble)
- I was awarded the [https://www.fondation-hadamard.fr/fr/pgmo/students/phdawards Programme Gaspard Monge Optimisation] PhD prize!
- I was awarded [https://www.telecom-paris.fr/fr/doctorat/grade/prix-de-these Telecom Paris' 2020 PhD prize]! A warm thank you to my advisors Alexandre Gramfort, Joseph Salmon and coauthor Quentin Bertrand
- We recently started the [https://github.com/benchopt/benchopt benchopt] package to automate benchmarks of optimization algorithms on popular Machine Learning tasks
- I defended my PhD! Slides are [./assets/pdf/slides_defense.pdf here], and [https://tel.archives-ouvertes.fr/tel-02401628 here] is the manuscript. Starting next January I'll be a postdoc in Lorenzo Rosasco's Lab in Genova
- I joined [http://ibis.t.u-tokyo.ac.jp/suzuki/ Taiji Suzuki's lab] for an internship in Tokyo from Feb. 2019 to May 2019
