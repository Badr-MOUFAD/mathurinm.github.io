<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Teaching</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-item"><a href="teaching.html" class="current">Teaching</a></div>
<div class="menu-category">Useful links</div>
<div class="menu-item"><a href="https://github.com/mathurinm/">GitHub</a></div>
<div class="menu-item"><a href="https://stackoverflow.com/users/2902280/p-camilleri">StackOverflow</a></div>
<div class="menu-item"><a href="https://uk.linkedin.com/in/mathurin-massias-67434883">Linkedin</a></div>
<div class="menu-item"><a href="https://scholar.google.com/citations?user=kaTDZS0AAAAJ">Google&nbsp;Scholar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Teaching</h1>
</div>
<p>Material for the two labs can be downloaded <a href="https://filesender.renater.fr/?s=download&amp;token=1d569af5-6651-43d3-9e5f-c35db82b0e5b" target=&ldquo;blank&rdquo;>from here</a>.
Slides are <a href="./assets/2023_olissipo/olissipo_slides.pdf" target=&ldquo;blank&rdquo;>here</a>.
</p>
<h2>Optimization for large scale Machine Learning, M2 ENS 2022-2023 &amp; 2023-2024</h2>
<p>The goal of the class is to cover theoretical aspects and practical Python implementations of popular optimization algorithms in machine learning, with a focus on modern topics: huge scale models, automatic differentiation, deep learning, implicit bias, etc.
</p>
<p><b>Notes for the class</b> in their 2022 version are <a href="./assets/2022_ens/class.pdf" target=&ldquo;blank&rdquo;>here</a> and exercises are <a href="./assets/2022_ens/exos.pdf" target=&ldquo;blank&rdquo;>here</a>
</p>
<p><b>Schedule</b>: From November 21st onwards: Tuesday 08 h 00, Friday 13 h 30 (room B1).
</p>
<p><b>Validation</b>: weekly theoretical homeworks, labs and paper presentation at the end of the class.
</p>
<p><b>Ressources</b>:
</p>
<ul>
<li><p><i>Introductory lectures on convex optimization: a basic course</i>, Y. Nesterov, 2004. A reference book in optimization, updated in 2018: <i>Lectures on Convex Optimization</i>.
</p>
</li>
<li><p><i>First order methods in optimization</i>, A. Beck, 2019.
</p>
</li>
<li><p><i>Convex optimization: algorithms and complexity</i>, S. Bubeck, 2015. A short monograph (100 pages) covering basic topics.
</p>
</li>
</ul>
<h2>OLISSIPO Winter school: dimensionality reduction (02/2023)</h2>
<h2>Convex optimization @Computation and Modelling summer school, WUST 2022</h2>
<ul>
<li><p><a href="./assets/2022_wust/slides_intro.pdf" target=&ldquo;blank&rdquo;>intro slides</a>
</p>
</li>
<li><p><a href="./assets/2022_wust/exos.pdf" target=&ldquo;blank&rdquo;>exercises</a> (updated every day)
</p>
</li>
<li><p><a href="./assets/2022_wust/Lecture1_gd_ols.ipynb" target=&ldquo;blank&rdquo;>notebook 1 (Introduction to gradient descent on least squares)</a>
</p>
</li>
<li><p><a href="./assets/2022_wust/Lecture2_generic_GD.ipynb" target=&ldquo;blank&rdquo;>notebook 2 (Gradient descent on generic functions)</a>
</p>
</li>
<li><p><a href="./assets/2022_wust/Lecture3_nonsmooth.ipynb" target=&ldquo;blank&rdquo;>notebook 3 (Non smooth optimization: the proximal gradient algorithm)</a>
</p>
</li>
<li><p><a href="./assets/2022/wust/Lecture4_Newton_CD.ipynb" target=&ldquo;blank&rdquo;>notebook 4 (Alternatives to gradient descent)</a>
</p>
</li>
</ul>
<h2>Resources</h2>
<p>My colleague <a href="https://pierreablin.com/" target=&ldquo;blank&rdquo;>Pierre Ablin</a> and I have created a repository with some Python advice for our students:
<a href="https://github.com/pierreablin/python-sessions" target=&ldquo;blank&rdquo;>https://github.com/pierreablin/python-sessions</a>.
</p>
<h2>Classes taught</h2>
<p>Since 2019, I teach the <a href="https://moodle.polytechnique.fr/course/view.php?id=7524" target=&ldquo;blank&rdquo;>Python for datascience</a> class (42 h per year) in the X/HEC &ldquo;Datascience for business&rdquo; Master, using live coding  inspired by the Software Carpentry workshops. I designed the course from scratch, collaborating  with Joan Massich in 2019, Quentin Bertrand in 2020, and Hicham Janati in 2021.
</p>
<p>Since 2020 I teach and handle practical sessions and data camps in Ecole Polytechnique's <a href="https://portail.polytechnique.edu/datascience/en/programs/data-science-starter-program-dssp" target=&ldquo;blank&rdquo;>Executive education</a> (70 h).
Topics involved dimension reduction, clustering, scaling computations, visualization and datacamp. I designed 2 full python labs with Erwan Le Pennec on these topics.
</p>
<p>From 2017 to 2019, my main teaching activity was the Optimization for datascience class of the <a href="https://www.universite-paris-saclay.fr/formation/master/mathematiques-et-applications/m2-data-sciences" target=&ldquo;blank&rdquo;>Datascience Master</a>, totalling 2*40 h including 4 h as lecturer.
Amongst others, this involved refactoring of the practical sessions, tutoring of students during office hours, and partaking in the design of the final exam.
</p>
<p>In 2016-2017, I was a TA at Télécom Paris, for
</p>
<ul>
<li><p>Analysis and Probabilities (MDI 113/114, Bachelor, 10 h)
</p>
</li>
<li><p>Machine Learning and Data Mining (MDI 343, Executive Master, 20 h)
</p>
</li>
<li><p>Linear Models (SD 204, Master, 10 h)
</p>
</li>
<li><p>Practical Machine Learning (SD 207, Master, 10 h)
</p>
</li>
<li><p>Tools and applications for signals and images (SI 101, Bachelor, 6 h)
</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
