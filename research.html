<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title></title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-category">useful links</div>
<div class="menu-item"><a href="https://github.com/mathurinm/">GitHub</a></div>
<div class="menu-item"><a href="https://stackoverflow.com/users/2902280/p-camilleri">StackOverflow</a></div>
<div class="menu-item"><a href="https://uk.linkedin.com/in/mathurin-massias-67434883">Linkedin</a></div>
</td>
<td id="layout-content">
<h2>PhD. Thesis</h2>
<ul>
<li><p><b>M. Massias</b>, Sparse high dimension linear regression in the presence of heteroscedastic noise: application to magnetoelectric source imaging. Defended on 04/12/2019.
<a target="_blank" rel="noopener noreferrer" href="https://tel.archives-ouvertes.fr/tel-02401628">manuscript</a>
<a target="_blank" rel="noopener noreferrer" href="./assets/pdf/slides_defense.pdf">slides</a></p>
</li>
</ul>
<h2>Papers</h2>
<ul>
<li><p>2021</p>
<ul>
<li><p>Q. Bertrand, <b>M. Massias</b>, <a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2011.10065">Anderson acceleration of coordinate descent</a>, to appear in AISTATS 2021. <a target="_blank" rel="noopener noreferrer" href="https://mathurinm.github.io/andersoncd">code</a></p>
</li>
<li><p>C. Molinari, <b>M. Massias</b>, L. Rosasco, S. Villa,
<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2006.09859">Iterative regularization for convex regularizers</a>, to appear in AISTATS 2021. <a target="_blank" rel="noopener noreferrer" href="https://LCSL.github.io/iterreg">code</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2020</p>
<ul>
<li><p><b>M. Massias</b>*, Q. Bertrand*, A. Gramfort, J. Salmon,
<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/2001.05401">Support recovery and sup-norm convergence rates for sparse pivotal estimation</a>, AISTATS 2020.</p>
</li>
<li><p><b>M. Massias</b>, S. Vaiter, A. Gramfort, J. Salmon,
<a target="_blank" rel="noopener noreferrer" href="https://jmlr.org/papers/v21/19-587.html">Dual extrapolation for sparse Generalized Linear Models</a>, JMLR. <a target="_blank" rel="noopener noreferrer" href="https://github.com/mathurinm/celer">celer library</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2019</p>
<ul>
<li><p>P. Ablin, T. Moreau, <b>M. Massias</b>, A. Gramfort,
<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1905.11071">Learning step sizes for unfolded sparse coding</a>, NeurIPS 2019.</p>
</li>
<li><p>Q. Bertrand*, <b>M. Massias</b>*, A. Gramfort, J. Salmon,
<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1902.02509">Handling correlated and repeated measurements with the smoothed multivariate square-root Lasso</a>, NeurIPS 2019.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/QBE/clar">code</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2018</p>
<ul>
<li><p><b>M. Massias</b>, A. Gramfort, J. Salmon,
<a target="_blank" rel="noopener noreferrer" href="http://proceedings.mlr.press/v80/massias18a.html">Celer: a fast solver for the Lasso with dual extrapolation</a>,
ICML 2018.
<a target="_blank" rel="noopener noreferrer" href="https://drive.google.com/file/d/1doIoZ2dahVNhxFhLqHOwK_VfdOQrZjj6/view?usp=sharing">slides</a>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mathurinm/celer">code</a>
<a target="_blank" rel="noopener noreferrer" href="https://mathurinm.github.io/celer/">doc</a></p>
</li>
<li><p><b>M. Massias</b>, O. Fercoq, A. Gramfort, J. Salmon,
<a target="_blank" rel="noopener noreferrer" href="http://proceedings.mlr.press/v84/massias18a.html">Generalized
concomitant multi-task Lasso for sparse multimodal regression</a>,
AISTATS 2018.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mathurinm/SHCL">code</a></p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>2017</p>
<ul>
<li><p><b>M. Massias</b>, A. Gramfort, J. Salmon,
<a target="_blank" rel="noopener noreferrer" href="https://arxiv.org/abs/1703.07285">From safe screening rules to working sets
for faster Lasso-type solvers</a>,
OPTML workshop at NIPS 2017.
<a target="_blank" rel="noopener noreferrer" href="https://github.com/mathurinm/A5G">deprecated code</a></p>
</li>
<li><p><b>M. Massias</b>, J. Salmon, A. Gramfort,
<a target="_blank" rel="noopener noreferrer" href="http://spars2017.lx.it.pt/index_files/papers/SPARS2017_Paper_77.pdf">Gap safe screening rules for faster complex-valued multi-task group Lasso</a>,
SPARS, Lisbon, 2017.
<a target="_blank" rel="noopener noreferrer" href="https://goo.gl/kW8EXy">poster</a></p>
</li>
</ul>

</li>
</ul>
<h2>Relevant slides</h2>
<ul>
<li><p><a target="_blank" rel="noopener noreferrer" href="./assets/pdf/cirm_mathurin.pdf">Dual extrapolation</a>, 09/03/2020, Optimization for Machine Learning workshop at CIRM, Luminy.</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="./assets/pdf/bounds_aistats20_slides.pdf">LCSL group meeting</a>, 23/01/2020, Università di Genova.</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="./assets/pdf/slides_defense.pdf">PhD Defense</a>, 04/12/2019, Inria.</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="./assets/pdf/AIP2019.pdf">Dual extrapolation for sparse Generalized Linear Models</a>,
09/07/2019, Applied Inverse Problems conference, Grenoble.</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="./assets/pdf/uw_mm.pdf">Celer: fast solver for the Lasso with dual extrapolation</a>,
11/05/2018, Statistics Seminar at University of Washington.</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="https://goo.gl/hZRwqi">Generalized concomitant multi-task Lasso for sparse multimodal regression</a>,
20/10/2017, Journées GDR MOA MIA (Bordeaux).
Also presented at PGMO days 2017, Saclay.</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="https://goo.gl/wACD2h">Résolution rapide de problèmes de type Lasso: des règles de safe screening aux working sets</a> (in French), 05/09/2017, GRETSI.
Also presented at JDSE 2017 (best presentation award).</p>
</li>
<li><p><a target="_blank" rel="noopener noreferrer" href="https://goo.gl/8m0a8s">Faster solvers for sparse multi-task problems</a>, 20/03/2017, IAP (Paris).
Also presented at CMStats 2017, London.</p>
</li>
</ul>
</td>
</tr>
</table>
</body>
</html>
